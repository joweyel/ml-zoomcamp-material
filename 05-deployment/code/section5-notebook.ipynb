{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Deploying Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rs = 1 # random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-week-3.csv\")\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "categorical_columns = list(df.dtypes[df.dtypes == \"object\"].index)\n",
    "\n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "df[\"totalcharges\"] = pd.to_numeric(df[\"totalcharges\"], errors=\"coerce\")\n",
    "df[\"totalcharges\"] = df[\"totalcharges\"].fillna(0)\n",
    "\n",
    "df[\"churn\"] = (df[\"churn\"] == \"yes\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [\"tenure\", \"monthlycharges\", \"totalcharges\"]\n",
    "\n",
    "categorical = [\n",
    "    \"gender\",\n",
    "    \"seniorcitizen\",\n",
    "    \"partner\",\n",
    "    \"dependents\",\n",
    "    \"phoneservice\",\n",
    "    \"multiplelines\",\n",
    "    \"internetservice\",\n",
    "    \"onlinesecurity\",\n",
    "    \"onlinebackup\",\n",
    "    \"deviceprotection\",\n",
    "    \"techsupport\",\n",
    "    \"streamingtv\",\n",
    "    \"streamingmovies\",\n",
    "    \"contract\",\n",
    "    \"paperlessbilling\",\n",
    "    \"paymentmethod\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "    \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "    model = LogisticRegression(C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC(1): 0.844\n",
      "AUC(2): 0.846\n",
      "AUC(3): 0.832\n",
      "AUC(4): 0.830\n",
      "AUC(5): 0.852\n",
      "C =  1.0 | 0.841 +- 0.008\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=rs)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kfold.split(df_full_train)):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train[\"churn\"].values\n",
    "    y_val = df_val[\"churn\"].values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "    print(f\"AUC({i+1}): {auc:.3f}\")\n",
    "\n",
    "print(f\"C = {C:4} | {np.mean(scores):.3f} +- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC(full): 0.857\n"
     ]
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train[\"churn\"].values, C=1.0)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "y_test = df_test[\"churn\"].values\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC(full): {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code until here was taken from previous weeks. Now we want to save the model in order to use it further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Saving and loading the model\n",
    "\n",
    "- Saving the model to `pickle`\n",
    "- Loading the model from `pickle`\n",
    "- Turning our notebook into a Python script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the model with `pickle`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_C=1.0.bin'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = f\"model_C={C}.bin\"\n",
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dv is also important for preprocessing of model-inputs\n",
    "# and is saved alongside with the model\n",
    "with open(output_file, 'wb') as f_out:\n",
    "    pickle.dump((dv, model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the model from `pickle`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"model_C=1.0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_file, \"rb\") as f_in:\n",
    "    dv, model = pickle.load(f_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(max_iter=1000))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turning our notebook into a Python script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning the customer (singular dictionary of data) into a feature matrix with the saved `DictVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dv.transform([customer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the saved model for predictiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.636 | Churn: True\n"
     ]
    }
   ],
   "source": [
    "y_customer = model.predict_proba(X)[0, 1]\n",
    "print(f\"p = {y_customer:.3f} | Churn: {y_customer >= 0.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the Notebook as Python-file:\n",
    "- Using the save as function of the web-version of Jupyter notebook\n",
    "- Using the console: `jupyter nbconvert --to python notebook.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Code from this notebook is split into the\n",
    "- Traingin script: [train.py](./train.py)\n",
    "- Prediction script: [predict.py](./predict.py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
